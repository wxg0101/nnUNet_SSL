{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/oem/2f92ffc8-5cb4-410e-a267-5f20ebf74ea1/miniconda3/envs/wxg/lib/python3.7/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Please cite the following paper when using nnUNet:\n",
      "\n",
      "Isensee, F., Jaeger, P.F., Kohl, S.A.A. et al. \"nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation.\" Nat Methods (2020). https://doi.org/10.1038/s41592-020-01008-z\n",
      "\n",
      "\n",
      "If you have questions or suggestions, feel free to open an issue at https://github.com/MIC-DKFZ/nnUNet\n",
      "\n",
      "nnUNet_raw_data_base is not defined and nnU-Net can only be used on data for which preprocessed files are already present on your system. nnU-Net cannot be used for experiment planning and preprocessing like this. If this is not intended, please read documentation/setting_up_paths.md for information on how to set this up properly.\n",
      "nnUNet_preprocessed is not defined and nnU-Net can not be used for preprocessing or training. If this is not intended, please read documentation/setting_up_paths.md for information on how to set this up.\n",
      "RESULTS_FOLDER is not defined and nnU-Net cannot be used for training or inference. If this is not intended behavior, please read documentation/setting_up_paths.md for information on how to set this up.\n"
     ]
    }
   ],
   "source": [
    "from batchgenerators.utilities.file_and_folder_operations import *\n",
    "from _warnings import warn\n",
    "from tqdm import trange\n",
    "from time import time, sleep\n",
    "from collections import OrderedDict\n",
    "from typing import Tuple\n",
    "import torch.backends.cudnn as cudnn\n",
    "import numpy as np\n",
    "import torch\n",
    "from nnunet.training.data_augmentation.data_augmentation_moreDA import get_moreDA_augmentation\n",
    "from nnunet.training.loss_functions.deep_supervision import MultipleOutputLoss2\n",
    "from nnunet.utilities.to_torch import maybe_to_torch, to_cuda\n",
    "from nnunet.network_architecture.generic_UNet import Generic_UNet\n",
    "from nnunet.network_architecture.initialization import InitWeights_He\n",
    "from nnunet.network_architecture.neural_network import SegmentationNetwork\n",
    "from nnunet.training.data_augmentation.default_data_augmentation import default_2D_augmentation_params, \\\n",
    "    get_patch_size, default_3D_augmentation_params\n",
    "from nnunet.training.dataloading.dataset_loading import unpack_dataset\n",
    "from nnunet.training.network_training.nnUNetTrainer import nnUNetTrainer\n",
    "from nnunet.utilities.nd_softmax import softmax_helper\n",
    "from sklearn.model_selection import KFold\n",
    "from torch import nn\n",
    "from torch.cuda.amp import autocast\n",
    "from nnunet.training.learning_rate.poly_lr import poly_lr\n",
    "from batchgenerators.utilities.file_and_folder_operations import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "network = Generic_UNet(3, 32, 2,\n",
    "                                    6,\n",
    "                                    2, 2, nn.Conv2d, nn.InstanceNorm2d, {'eps': 1e-5, 'affine': True}, nn.Dropout2d,\n",
    "                                    {'p': 0, 'inplace': True},\n",
    "                                    nn.LeakyReLU, {'negative_slope': 1e-2, 'inplace': True}, True, False, lambda x: x, InitWeights_He(1e-2),\n",
    "                                   [[2, 2], [2, 2], [2, 2], [2, 2], [2, 2], [2, 2]], [[3, 3], [3, 3], [3, 3], [3, 3], [3, 3], [3, 3], [3, 3]], False, True, True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.randn(2,3,256,256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=network(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 2, 8, 8])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[5].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.13 ('wxg')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "6484d56f2ff3433d805894b8ff28b925df64d6de990f535bc41df2e8d70961ec"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
